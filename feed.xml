<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>Atharva&#x27;s Blog</title>
    <link href="https://Atharva-Attarde.github.io/feed.xml" rel="self" />
    <link href="https://Atharva-Attarde.github.io" />
    <updated>2025-07-16T21:20:21+05:30</updated>
    <author>
        <name>Atharva Attarde</name>
    </author>
    <id>https://Atharva-Attarde.github.io</id>

    <entry>
        <title>A Simple Technique to Get Segmentation Masks for Choroid Vessels</title>
        <author>
            <name>Atharva Attarde</name>
        </author>
        <link href="https://Atharva-Attarde.github.io/a-simple-technique-to-get-segmentation-masks-for-choroid-vessels-2.html"/>
        <id>https://Atharva-Attarde.github.io/a-simple-technique-to-get-segmentation-masks-for-choroid-vessels-2.html</id>
        <media:content url="https://Atharva-Attarde.github.io/media/posts/6/0045.png" medium="image" />
            <category term="OCT, Choroid"/>

        <updated>2025-07-16T21:12:02+05:30</updated>
            <summary>
                <![CDATA[
                        <img src="https://Atharva-Attarde.github.io/media/posts/6/0045.png" alt="" />
                    The choroid is an important part of the eye and is clearly visible in OCT B-scan images. Segmenting the entire choroid region is already a well-solved problem SOTA benchmarks are more or less saturated. But the real challenge now is to go one level deeper:&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://Atharva-Attarde.github.io/media/posts/6/0045.png" class="type:primaryImage" alt="" /></p>
                <p data-start="245" data-end="447">The choroid is an important part of the eye and is clearly visible in OCT B-scan images. Segmenting the entire choroid region is already a well-solved problem SOTA benchmarks are more or less saturated.</p>
<p data-start="449" data-end="735">But the real challenge now is to go one level deeper: segmenting specific structures <em data-start="534" data-end="542">within</em> the choroid. In particular, the choroidal vasculature is a crucial biomarker, and being able to extract the vessel structure from the choroid region could have important clinical implications.</p>
<p data-start="737" data-end="1132">The latest paper I came across on this topic is by <a href="https://rdcu.be/ewuxC" target="_blank" rel="noopener noreferrer">Valsecchi, N</a> , where they’ve used Phansalkar thresholding to extract the vessels. But I noticed that this doesn’t work well for all images. In some cases like the one below you can clearly see the vessels, but due to speckle noise, there are a lot of false bright spots scattered in the dark vessel regions. These are misleading and break the mask quality.</p>
<figure ><figure class="post__image post__image--center"><img loading="lazy"  src="https://Atharva-Attarde.github.io/media/posts/6/Original-Image-2.png" alt="Original B scan" width="392" height="407" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-xs.png 640w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-sm.png 768w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-md.png 1024w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-lg.png 1366w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-xl.png 1600w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-2xl.png 1920w"></figure>
<figcaption >Original B Scan</figcaption>
</figure>
<p data-start="737" data-end="1132"> </p>
<p data-start="1134" data-end="1425">Another issue is that <strong data-start="1156" data-end="1212">hand-annotating these vessels is extremely expensive</strong>. The vessels are thin, irregular, and scattered across noisy regions, which makes consistent manual labeling both time-consuming and error-prone. So the need for automatic or semi-automatic methods is quite real.</p>
<p data-start="1427" data-end="1592">To tackle the noise problem, I tried several methods NLM, BM3D, Noise2Void, etc. and finally settled on a really simple pipeline that gave surprisingly good results.</p>
<h3 data-start="1599" data-end="1616">The Technique</h3>
<p data-start="1618" data-end="1762">We start with a predicted choroid mask from a SOTA model or hand annotated region (you can use <strong><a href="https://github.com/justinengelmann/Choroidalyzer" target="_blank" rel="noopener noreferrer">Choroidalyzer </a></strong>)and extract only that region from the OCT image.</p>
<figure ><figure class="post__image post__image--center"><img loading="lazy"  src="https://Atharva-Attarde.github.io/media/posts/6/extracted_0045.png" alt="Extracted choroid region" width="512" height="512" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-xs.png 640w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-sm.png 768w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-md.png 1024w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-lg.png 1366w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-xl.png 1600w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-2xl.png 1920w"></figure>
<figcaption >Extracted choroid region</figcaption>
</figure>
<p data-start="1618" data-end="1762"> </p>
<p data-start="1618" data-end="1762">Then, we apply iterative refinement:</p>
<ol data-start="1764" data-end="2000">
<li data-start="1764" data-end="1800">
<p data-start="1767" data-end="1800"><strong data-start="1767" data-end="1798">Apply Non-Local Means (NLM)</strong></p>
</li>
<li data-start="1801" data-end="1872">
<p data-start="1804" data-end="1872"><strong data-start="1804" data-end="1870">Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)</strong></p>
</li>
<li data-start="1873" data-end="2000">
<p data-start="1876" data-end="2000"><strong data-start="1876" data-end="1903">Apply Otsu Thresholding</strong>  we exclude the black background pixels so they don’t skew the threshold.</p>
</li>
</ol>
<p data-start="2002" data-end="2086">This whole sequence can be repeated for a few iterations to refine the mask further.</p>
<p data-start="2088" data-end="2126">Here’s the code:</p>
<div>
<div><code>import cv2</code></div>
<div><code>import matplotlib.pyplot as plt</code></div>
<br>
<div><code>image = cv2.imread(r"C:\Users\Atharva\Desktop\Archive\OCT\OIHMS DATASET SEPERATED\extracted_masked_regions\extracted_0045.png", cv2.IMREAD_GRAYSCALE)</code></div>
<div><code># Start with the original image</code></div>
<div><code>img = image.copy()</code></div>
<br>
<div><code># Number of iterations</code></div>
<div><code>num_iterations = 5</code></div>
<br>
<div><code># Store results for visualization</code></div>
<div><code>results = [img]</code></div>
<div><code>otsu_results = [cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]]</code></div>
<br>
<div><code>for i in range(num_iterations):</code></div>
<div><code>    # Denoising</code></div>
<div><code>    img = cv2.fastNlMeansDenoising(img, h=10, templateWindowSize=7, searchWindowSize=14)</code></div>
<div><code>    # CLAHE</code></div>
<div><code>    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))</code></div>
<div><code>    img = clahe.apply(img)</code></div>
<div><code>    results.append(img)</code></div>
<div><code>    # Otsu thresholding</code></div>
<div><code>    # Create a mask that ignores black pixels (intensity 0)</code></div>
<div><code>    non_black_mask = img &gt; 0</code></div>
<br>
<div><code>    # Compute Otsu threshold only on non-zero pixels</code></div>
<div><code>    masked_pixels = img[non_black_mask]</code></div>
<div><code>    if masked_pixels.size &gt; 0:</code></div>
<div><code>        otsu_thresh = cv2.threshold(masked_pixels, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[0]</code></div>
<div><code>    else:</code></div>
<div><code>        otsu_thresh = 0  # fallback if image is all black</code></div>
<br>
<div><code>    # Apply threshold to full image using that threshold</code></div>
<div><code>    _, otsu_img = cv2.threshold(img, otsu_thresh, 255, cv2.THRESH_BINARY)</code></div>
<br>
<div><code>    otsu_results.append(otsu_img)</code></div>
<br>
<div><code># Plot all iterations and their Otsu results</code></div>
<div><code>plt.figure(figsize=(15, 8))</code></div>
<div><code>for idx, (res, otsu_img) in enumerate(zip(results, otsu_results)):</code></div>
<div><code>    plt.subplot(2, num_iterations + 1, idx + 1)</code></div>
<div><code>    plt.imshow(res, cmap='gray')</code></div>
<div><code>    if idx == 0:</code></div>
<div><code>        plt.title('Original')</code></div>
<div><code>    else:</code></div>
<div><code>        plt.title(f'Iter {idx}')</code></div>
<div><code>    plt.axis('off')</code></div>
<div><code>    plt.subplot(2, num_iterations + 1, idx + 1 + num_iterations + 1)</code></div>
<div><code>    plt.imshow(otsu_img, cmap='gray')</code></div>
<div><code>    plt.axis('off')</code></div>
<div><code>    if idx == 0:</code></div>
<div><code>        plt.title('Otsu')</code></div>
<div><code>    else:</code></div>
<div><code>        plt.title(f'Otsu {idx}')</code></div>
<div><code>plt.tight_layout()</code></div>
<div><code>plt.show()</code></div>
</div>
<h3 data-start="2133" data-end="2144">Results</h3>
<figure ><figure class="post__image post__image--wide"><img loading="lazy"  src="https://Atharva-Attarde.github.io/media/posts/6/Final-Out.png" alt="" width="1489" height="621" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-xs.png 640w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-sm.png 768w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-md.png 1024w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-lg.png 1366w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-xl.png 1600w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-2xl.png 1920w"></figure>
<figcaption >Pipeline Results</figcaption>
</figure>
<p data-start="2146" data-end="2192"> </p>
<h3 data-start="2199" data-end="2223">Notes and Discussion</h3>
<p data-start="2225" data-end="2478">One thing to keep in mind: the number of iterations matters. Over-iterating will start to introduce artifacts and may exaggerate vessel regions. </p>
<p data-start="2485" data-end="2654"> </p>
<p data-start="2485" data-end="2654"><strong data-start="2488" data-end="2507">Follow the blog</strong> - in the next post, we’ll explore <strong data-start="2542" data-end="2578">PU (Positive-Unlabeled) labeling</strong> to segment choroidal vessels even when annotations are incomplete or noisy.</p>
<p data-start="2656" data-end="2950">In real datasets, <strong data-start="2674" data-end="2708">annotations are rarely perfect </strong>some vessels are missed, others are loosely outlined. With PU learning, we’ll try to train models that treat the labeled vessels as <em data-start="2841" data-end="2852">positives</em> and the rest as <em data-start="2869" data-end="2880">unlabeled </em>helping the model learn the full structure even from imperfect masks.</p>
            ]]>
        </content>
    </entry>
</feed>

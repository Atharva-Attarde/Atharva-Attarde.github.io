{
    "version": "https://jsonfeed.org/version/1",
    "title": "Atharva&#x27;s Blog",
    "description": "",
    "home_page_url": "https://Atharva-Attarde.github.io",
    "feed_url": "https://Atharva-Attarde.github.io/feed.json",
    "user_comment": "",
    "author": {
        "name": "Atharva Attarde"
    },
    "items": [
        {
            "id": "https://Atharva-Attarde.github.io/a-simple-technique-to-get-segmentation-masks-for-choroid-vessels-2.html",
            "url": "https://Atharva-Attarde.github.io/a-simple-technique-to-get-segmentation-masks-for-choroid-vessels-2.html",
            "title": "A Simple Technique to Get Segmentation Masks for Choroid Vessels",
            "summary": "The choroid is an important part of the eye and is clearly visible in OCT B-scan images. Segmenting the entire choroid region is already a well-solved problem SOTA benchmarks are more or less saturated. But the real challenge now is to go one level deeper:&hellip;",
            "content_html": "<p data-start=\"245\" data-end=\"447\">The choroid is an important part of the eye and is clearly visible in OCT B-scan images. Segmenting the entire choroid region is already a well-solved problem SOTA benchmarks are more or less saturated.</p>\n<p data-start=\"449\" data-end=\"735\">But the real challenge now is to go one level deeper: segmenting specific structures <em data-start=\"534\" data-end=\"542\">within</em> the choroid. In particular, the choroidal vasculature is a crucial biomarker, and being able to extract the vessel structure from the choroid region could have important clinical implications.</p>\n<p data-start=\"737\" data-end=\"1132\">The latest paper I came across on this topic is by <a href=\"https://rdcu.be/ewuxC\" target=\"_blank\" rel=\"noopener noreferrer\">Valsecchi, N</a> , where they’ve used Phansalkar thresholding to extract the vessels. But I noticed that this doesn’t work well for all images. In some cases like the one below you can clearly see the vessels, but due to speckle noise, there are a lot of false bright spots scattered in the dark vessel regions. These are misleading and break the mask quality.</p>\n<figure ><figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://Atharva-Attarde.github.io/media/posts/6/Original-Image-2.png\" alt=\"Original B scan\" width=\"392\" height=\"407\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-xs.png 640w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-sm.png 768w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-md.png 1024w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-lg.png 1366w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-xl.png 1600w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Original-Image-2-2xl.png 1920w\"></figure>\n<figcaption >Original B Scan</figcaption>\n</figure>\n<p data-start=\"737\" data-end=\"1132\"> </p>\n<p data-start=\"1134\" data-end=\"1425\">Another issue is that <strong data-start=\"1156\" data-end=\"1212\">hand-annotating these vessels is extremely expensive</strong>. The vessels are thin, irregular, and scattered across noisy regions, which makes consistent manual labeling both time-consuming and error-prone. So the need for automatic or semi-automatic methods is quite real.</p>\n<p data-start=\"1427\" data-end=\"1592\">To tackle the noise problem, I tried several methods NLM, BM3D, Noise2Void, etc. and finally settled on a really simple pipeline that gave surprisingly good results.</p>\n<h3 data-start=\"1599\" data-end=\"1616\">The Technique</h3>\n<p data-start=\"1618\" data-end=\"1762\">We start with a predicted choroid mask from a SOTA model or hand annotated region (you can use <strong><a href=\"https://github.com/justinengelmann/Choroidalyzer\" target=\"_blank\" rel=\"noopener noreferrer\">Choroidalyzer </a></strong>)and extract only that region from the OCT image.</p>\n<figure ><figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://Atharva-Attarde.github.io/media/posts/6/extracted_0045.png\" alt=\"Extracted choroid region\" width=\"512\" height=\"512\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-xs.png 640w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-sm.png 768w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-md.png 1024w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-lg.png 1366w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-xl.png 1600w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/extracted_0045-2xl.png 1920w\"></figure>\n<figcaption >Extracted choroid region</figcaption>\n</figure>\n<p data-start=\"1618\" data-end=\"1762\"> </p>\n<p data-start=\"1618\" data-end=\"1762\">Then, we apply iterative refinement:</p>\n<ol data-start=\"1764\" data-end=\"2000\">\n<li data-start=\"1764\" data-end=\"1800\">\n<p data-start=\"1767\" data-end=\"1800\"><strong data-start=\"1767\" data-end=\"1798\">Apply Non-Local Means (NLM)</strong></p>\n</li>\n<li data-start=\"1801\" data-end=\"1872\">\n<p data-start=\"1804\" data-end=\"1872\"><strong data-start=\"1804\" data-end=\"1870\">Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)</strong></p>\n</li>\n<li data-start=\"1873\" data-end=\"2000\">\n<p data-start=\"1876\" data-end=\"2000\"><strong data-start=\"1876\" data-end=\"1903\">Apply Otsu Thresholding</strong>  we exclude the black background pixels so they don’t skew the threshold.</p>\n</li>\n</ol>\n<p data-start=\"2002\" data-end=\"2086\">This whole sequence can be repeated for a few iterations to refine the mask further.</p>\n<p data-start=\"2088\" data-end=\"2126\">Here’s the code:</p>\n<div>\n<div><code>import cv2</code></div>\n<div><code>import matplotlib.pyplot as plt</code></div>\n<br>\n<div><code>image = cv2.imread(r\"C:\\Users\\Atharva\\Desktop\\Archive\\OCT\\OIHMS DATASET SEPERATED\\extracted_masked_regions\\extracted_0045.png\", cv2.IMREAD_GRAYSCALE)</code></div>\n<div><code># Start with the original image</code></div>\n<div><code>img = image.copy()</code></div>\n<br>\n<div><code># Number of iterations</code></div>\n<div><code>num_iterations = 5</code></div>\n<br>\n<div><code># Store results for visualization</code></div>\n<div><code>results = [img]</code></div>\n<div><code>otsu_results = [cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]]</code></div>\n<br>\n<div><code>for i in range(num_iterations):</code></div>\n<div><code>    # Denoising</code></div>\n<div><code>    img = cv2.fastNlMeansDenoising(img, h=10, templateWindowSize=7, searchWindowSize=14)</code></div>\n<div><code>    # CLAHE</code></div>\n<div><code>    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))</code></div>\n<div><code>    img = clahe.apply(img)</code></div>\n<div><code>    results.append(img)</code></div>\n<div><code>    # Otsu thresholding</code></div>\n<div><code>    # Create a mask that ignores black pixels (intensity 0)</code></div>\n<div><code>    non_black_mask = img &gt; 0</code></div>\n<br>\n<div><code>    # Compute Otsu threshold only on non-zero pixels</code></div>\n<div><code>    masked_pixels = img[non_black_mask]</code></div>\n<div><code>    if masked_pixels.size &gt; 0:</code></div>\n<div><code>        otsu_thresh = cv2.threshold(masked_pixels, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[0]</code></div>\n<div><code>    else:</code></div>\n<div><code>        otsu_thresh = 0  # fallback if image is all black</code></div>\n<br>\n<div><code>    # Apply threshold to full image using that threshold</code></div>\n<div><code>    _, otsu_img = cv2.threshold(img, otsu_thresh, 255, cv2.THRESH_BINARY)</code></div>\n<br>\n<div><code>    otsu_results.append(otsu_img)</code></div>\n<br>\n<div><code># Plot all iterations and their Otsu results</code></div>\n<div><code>plt.figure(figsize=(15, 8))</code></div>\n<div><code>for idx, (res, otsu_img) in enumerate(zip(results, otsu_results)):</code></div>\n<div><code>    plt.subplot(2, num_iterations + 1, idx + 1)</code></div>\n<div><code>    plt.imshow(res, cmap='gray')</code></div>\n<div><code>    if idx == 0:</code></div>\n<div><code>        plt.title('Original')</code></div>\n<div><code>    else:</code></div>\n<div><code>        plt.title(f'Iter {idx}')</code></div>\n<div><code>    plt.axis('off')</code></div>\n<div><code>    plt.subplot(2, num_iterations + 1, idx + 1 + num_iterations + 1)</code></div>\n<div><code>    plt.imshow(otsu_img, cmap='gray')</code></div>\n<div><code>    plt.axis('off')</code></div>\n<div><code>    if idx == 0:</code></div>\n<div><code>        plt.title('Otsu')</code></div>\n<div><code>    else:</code></div>\n<div><code>        plt.title(f'Otsu {idx}')</code></div>\n<div><code>plt.tight_layout()</code></div>\n<div><code>plt.show()</code></div>\n</div>\n<h3 data-start=\"2133\" data-end=\"2144\">Results</h3>\n<figure ><figure class=\"post__image post__image--wide\"><img loading=\"lazy\"  src=\"https://Atharva-Attarde.github.io/media/posts/6/Final-Out.png\" alt=\"\" width=\"1489\" height=\"621\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-xs.png 640w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-sm.png 768w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-md.png 1024w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-lg.png 1366w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-xl.png 1600w ,https://Atharva-Attarde.github.io/media/posts/6/responsive/Final-Out-2xl.png 1920w\"></figure>\n<figcaption >Pipeline Results</figcaption>\n</figure>\n<p data-start=\"2146\" data-end=\"2192\"> </p>\n<h3 data-start=\"2199\" data-end=\"2223\">Notes and Discussion</h3>\n<p data-start=\"2225\" data-end=\"2478\">One thing to keep in mind: the number of iterations matters. Over-iterating will start to introduce artifacts and may exaggerate vessel regions. </p>\n<p data-start=\"2485\" data-end=\"2654\"> </p>\n<p data-start=\"2485\" data-end=\"2654\"><strong data-start=\"2488\" data-end=\"2507\">Follow the blog</strong> - in the next post, we’ll explore <strong data-start=\"2542\" data-end=\"2578\">PU (Positive-Unlabeled) labeling</strong> to segment choroidal vessels even when annotations are incomplete or noisy.</p>\n<p data-start=\"2656\" data-end=\"2950\">In real datasets, <strong data-start=\"2674\" data-end=\"2708\">annotations are rarely perfect </strong>some vessels are missed, others are loosely outlined. With PU learning, we’ll try to train models that treat the labeled vessels as <em data-start=\"2841\" data-end=\"2852\">positives</em> and the rest as <em data-start=\"2869\" data-end=\"2880\">unlabeled </em>helping the model learn the full structure even from imperfect masks.</p>",
            "image": "https://Atharva-Attarde.github.io/media/posts/6/0045.png",
            "author": {
                "name": "Atharva Attarde"
            },
            "tags": [
                   "OCT, Choroid"
            ],
            "date_published": "2025-07-16T21:12:02+05:30",
            "date_modified": "2025-07-16T21:20:21+05:30"
        }
    ]
}
